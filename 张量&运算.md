# 张量&运算

## 1.张量(tensor)

张量表示由数值组成的数组，创建的数组可能有多个维度。具有⼀个轴的张量对应数学上的向量（vector）； 具有两个轴的张量对应数学上的矩阵（matrix）；具有两个轴以上的张量没有特殊的数学名称。 

## 2.创建张量(tensor)

2.1 随机初始化矩阵，通过torch.randn()的方法，构造一个随机初始化的矩阵

```python
import torch

# 初始化矩阵
x = torch.randn(4, 3)
print(x)

# randn() 返回一个张量，其中填充了来自均值“0”和方差“1”（也称为标准正态分布）的正态分布的随机数
```

```python
tensor([[ 0.5972, -0.6283, -0.0439],
        [-0.6223,  0.3107,  0.4680],
        [-1.5478,  1.6934,  0.3533],
        [-0.8553,  2.2113,  1.6057]])
```

```python
>>> torch.randn(4)
tensor([-2.1436, 0.9966, 2.3426, -0.6366])

>>> torch.randn(2, 3)
tensor([[1.5954, 2.8929, -1.0923],
        [1.1719, -0.4709, -0.1996]])
```

2.2 全0矩阵构建，通过torch.zeros()构造一个矩阵全为0，并且通过dtype设置数据类型为long。还可以通过torch.zero_()和torch.zero_like()将现有的矩阵转换为全0的矩阵。

```python
import torch

# 创建全0矩阵（4 x 3）
x_1 = torch.zeros(4, 3, dtype = torch.long)
print(x_1)
```

```python
tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0]])
```

```python
>>> torch.zeros(2, 3)
tensor([[0., 0., 0.],
        [0., 0., 0.]])

>>> torch.zeros(5)
tensor([0., 0., 0., 0., 0.])
```

2.3 通过torch.tensor()直接创建并使用数据，构造一个张量

```python
import torch

x_2 = torch.tensor([1, 2, 3])
print(x_2)
```

```python
tensor([1, 2, 3])
```

```python
>>> torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])
tensor([[0.1000, 1.2000],
        [2.2000, 3.1000],
        [4.9000, 5.2000]])

>>> torch.tensor([0, 1])  # 数据类型推断
tensor([0, 1])

>>> torch.tensor([[0.11111, 0.222222, 0.3333333]],
                  ...
dtype = torch.float64,
        ...
device = torch.device('cuda:0'))  # 在 CUDA 设备上创建双张量
tensor([[0.1111, 0.2222, 0.3333]], dtype=torch.float64, device='cuda:0')

>>> torch.tensor(3.14159)  # 创建一个零维（标量）张量
tensor(3.1416)

>>> torch.tensor([])  # 创建一个空张量（大小为 (0,)）
tensor([])
```

2.4 通过numpy array数组进行创建

```python
import torch
import numpy as np

x_3 = np.array((1, 2, 3))
x_tensor_3 = torch.from_numpy(x_3) # 将np数组转换为张量
print(x_tensor_3)
```

```python
tensor([1, 2, 3], dtype=torch.int32)
```

2.5 基于已经存在的tensor，创建一个tensor

```python
import torch

x_4 = x.new_ones(4, 3, dtype=torch.double)
# 创建一个新的全1矩阵tensor，返回的tensor默认具有相同的torch.dtype和torch.device
# 也可以像之前的写法 x = torch.ones(4, 3, dtype=torch.double)

print(x)

x_5 = torch.randn_like(x, dtype=torch.float)
# 重置数据类型
print(x)
# 结果会有一样的size
# 获取它的维度信息
print(x_5.size())
print(x_5.shape)
```

```python
tensor([1, 2, 3], dtype=torch.int32)
tensor([[-2.2879, -0.0130,  0.2605],
        [ 0.3561,  0.7925,  0.7546],
        [-0.4286, -0.1336,  1.3082],
        [ 0.0418, -0.0130, -1.0453]])
tensor([[-2.2879, -0.0130,  0.2605],
        [ 0.3561,  0.7925,  0.7546],
        [-0.4286, -0.1336,  1.3082],
        [ 0.0418, -0.0130, -1.0453]])
torch.Size([4, 3])
torch.Size([4, 3])
```

返回的torch.Size其实是一个tuple，⽀持所有tuple的操作。可以使用索引操作取得张量的长、宽等数据维度。 

2.6 使用eye()方法，构造对角为1，其余为0的tensor

```python
import torch

x_6 = torch.eye(5, dtype=torch.float32)
print(x_6)
```

```python
tensor([[1., 0., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 0., 0., 0., 1.]])
```

```python
>> torch.eye(3)
tensor([[ 1.,  0.,  0.],
        [ 0.,  1.,  0.],
        [ 0.,  0.,  1.]])
```

2.7 使用arange(s, e, step)构建从s到e，步长为step的tensor

```python
import torch

x_7 = torch.arange(1, 10, 2, dtype=torch.float32)
print(x_7)
```

```python
tensor([1., 3., 5., 7., 9.])
```

```python
>>> torch.arange(5)
tensor([ 0,  1,  2,  3,  4])

>>> torch.arange(1, 4)
tensor([ 1,  2,  3])

>>> torch.arange(1, 2.5, 0.5)
tensor([ 1.0000,  1.5000,  2.0000])
```

2.8 使用linspace(s, e, steps)，构建从s到e，均匀分布成step份

```python
import torch

x_8 = torch.linspace(1, 10, 5, dtype=torch.float32)
print(x_8)
```

```python
tensor([ 1.0000,  3.2500,  5.5000,  7.7500, 10.0000])
```

```python
>>> torch.linspace(3, 10, steps=5)
tensor([  3.0000,   4.7500,   6.5000,   8.2500,  10.0000])

>>> torch.linspace(-10, 10, steps=5)
tensor([-10.,  -5.,   0.,   5.,  10.])

>>> torch.linspace(start=-10, end=10, steps=5)
tensor([-10.,  -5.,   0.,   5.,  10.])

>>> torch.linspace(start=-10, end=10, steps=1)
tensor([-10.])
```

2.9 rand 构建张量，返回一个由区间上均匀分布的随机数填充的张量：math:`[0, 1)` ，张量的形状由变量参数 :attr:`size` 定义

```python
import torch

x_9 = torch.rand(8)
print(x_9)
```

```python
>>> torch.rand(4)
tensor([ 0.5204,  0.2503,  0.3525,  0.5673])

 >>> torch.rand(2, 3)
 tensor([[ 0.8237,  0.5781,  0.6879],
         [ 0.3816,  0.7249,  0.0998]])
```

2.10 normal(mean, std, , generator=None, out=None) -> Tensor 返回从给出均值和标准差的独立正态分布中抽取的随机数张量。 

:attr:`mean` 是每个输出元素正态分布均值的张量 

:attr:`std` 是每个输出元素正态分布标准差的张量 

:attr:`mean` 和 : attr:`std` 不需要匹配，但每个张量中的元素总数需要相同

```python
>>> torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))
tensor([  1.0425,   3.5672,   2.7969,   4.2925,   4.7229,   6.2134,
        8.0505,   8.1408,   9.0563,  10.0566])

>>> torch.normal(mean=0.5, std=torch.arange(1., 6.))
tensor([-1.2793, -1.0732, -2.0687,  5.1177, -1.2303])

>>> torch.normal(mean=torch.arange(1., 6.))
tensor([ 1.1552,  2.6148,  2.6535,  5.8318,  4.2361])

>>> torch.normal(2, 3, size=(1, 4))
tensor([[-1.3987, -1.9544,  3.6048,  0.7909]])
```

2.11 randperm  从 0 返回整数的随机排列``到``n - 1

````python
>>> torch.randperm(4)
tensor([2, 1, 0, 3])
````

常见的构造Tensor的方法：

|        函数         |                       功能                        |
| :-----------------: | :-----------------------------------------------: |
|    Tensor(sizes)    |                   基础构造函数                    |
|    tensor(data)     |                  类似于np.array                   |
|     ones(sizes)     |                        全1                        |
|    zeros(sizes)     |                        全0                        |
|     eye(sizes)      |                 对角为1，其余为0                  |
|  arange(s,e,step)   |                从s到e，步长为step                 |
| linspace(s,e,steps) |              从s到e，均匀分成step份               |
|  rand/randn(sizes)  | rand是[0,1)均匀分布；randn是服从N(0，1)的正态分布 |
|  normal(mean,std)   |         正态分布(均值为mean，标准差是std)         |
|     randperm(m)     |                     随机排列                      |

## 3.张量运算

1.数学运行

```python
import torch
x_1 = torch.tensor((1, 2, 3))
x_2 = torch.tensor((4, 5, 6))

print(x_1 + x_2) # 加
print(x_1 - x_2) # 减
print(x_1 * x_2) # 乘
print(x_1 / x_2) # 除
print(x_1 % x_2) # 余
print(x_2 % x_1)
```

```python
tensor([5, 7, 9])
tensor([-3, -3, -3])
tensor([ 4, 10, 18])
tensor([0.2500, 0.4000, 0.5000])
tensor([1, 2, 3])
tensor([0, 1, 0]
```

```python
#加减乘除
"""
a + b = torch.add(a, b)
a - b = torch.sub(a, b)
a * b = torch.mul(a, b)
a / b = torch.div(a, b)
"""


import torch

a = torch.rand(3, 4)
b = torch.rand(4)
print(a)
# 输出：
    tensor([[0.6232, 0.5066, 0.8479, 0.6049],
            [0.3548, 0.4675, 0.7123, 0.5700],
            [0.8737, 0.5115, 0.2106, 0.5849]])

print(b)
# 输出：
    tensor([0.3309, 0.3712, 0.0982, 0.2331])
    
# 相加
# b会被广播
print(a + b)
# 输出：
    tensor([[0.9541, 0.8778, 0.9461, 0.8380],
            [0.6857, 0.8387, 0.8105, 0.8030],
            [1.2046, 0.8827, 0.3088, 0.8179]])   
# 等价于上面相加
print(torch.add(a, b))
# 输出：
    tensor([[0.9541, 0.8778, 0.9461, 0.8380],
            [0.6857, 0.8387, 0.8105, 0.8030],
            [1.2046, 0.8827, 0.3088, 0.8179]])  

# 比较两个是否相等
print(torch.all(torch.eq(a + b, torch.add(a, b))))
# 输出：
    tensor(True)    
```



2.矩阵相乘

```python
import torch

x_3 = torch.tensor((1, 2, 3, 4, 5))
x_4 = torch.tensor((9, 8, 7, 6, 5))

x_5 = x_3.dot(x_4) 
print(x_5) # 1x9 + 2x8 + 3x7 + 4x6 + 5x5 = tensor(95)

x_6 =x_3.multiply(x_4) 
print(x_6) # [1x9 , 2x8 , 3x7 , 4x6 , 5x5] = tensor([ 9, 16, 21, 24, 25])

x_7 = x_3.mul(x_4)
print(x_7) # [1x9 , 2x8 , 3x7 , 4x6 , 5x5] = tensor([ 9, 16, 21, 24, 25])

x_8 = torch.exp(x_3) # e = 2.718
print(x_8) # tensor([  2.7183,   7.3891,  20.0855,  54.5981, 148.4132])
```

```python
"""
torch.mm(a, b) # 此方法只适用于2维
torch.matmul(a, b)
a @ b = torch.matmul(a, b) # 推荐使用此方法
"""

a = torch.full((2, 2), 3)
print(a)
# 输出
    tensor([[3., 3.],
            [3., 3.]])

b = torch.ones(2, 2)
print(b)
# 输出
    tensor([[1., 1.],
            [1., 1.]])
    
print(torch.mm(a, b))
# 输出
    tensor([[6., 6.],
            [6., 6.]])

print(torch.matmul(a, b))
# 输出
    tensor([[6., 6.],
            [6., 6.]])
    
print(a @ b)
# 输出
    tensor([[6., 6.],
            [6., 6.]])    

```

3.幂计算

```python
"""
pow, sqrt, rsqrt
"""
a = torch.full([2, 2], 3)
print(a)
# 输出
    tensor([[3., 3.],
            [3., 3.]])
    
print(a.pow(2))
# 输出
    tensor([[9., 9.],
            [9., 9.]])    
    
aa = a ** 2
print(aa)
# 输出
    tensor([[9., 9.],
            [9., 9.]]) 
    
# 平方根
print(aa.sqrt())
# 输出
    tensor([[3., 3.],
            [3., 3.]])
# 平方根    
print(aa ** (0.5))
# 输出
    tensor([[3., 3.],
            [3., 3.]])    
# 平方根    
print(aa.pow(0.5))
# 输出
    tensor([[3., 3.],
            [3., 3.]])    
    
# 平方根的倒数
print(aa.rsqrt())
# 输出
    tensor([[0.3333, 0.3333],
            [0.3333, 0.3333]])        
tensor([[3., 3.],
        [3., 3.]])
```

4.限幅

```python
a.max() # 最大值
a.min() # 最小值
a.median() # 中位数
a.clamp(10) # 将最小值限定为10
a.clamp(0, 10) # 将数据限定在[0, 10]，两边都是闭区间
```

5.近似值

```python
a.floor() # 向下取整：floor，地板
a.ceil() # 向上取整：ceil，天花板
a.trunc() # 保留整数部分：truncate，截断
a.frac() # 保留小数部分：fraction，小数
a.round() # 四舍五入：round，大约
```

